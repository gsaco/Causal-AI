---
title: "Causal Discovery at Scale"
summary: "Interventions, weak supervision, and partial observability for large-scale causal graph discovery."
topics: ["causal-discovery", "latent-confounding-discovery", "identifiability-do-calculus"]
trends: ["discovery-at-scale"]
evidence_arxiv: ["1803.01422", "1705.08821", "1501.01332", "1907.02893", "2305.10032", "2406.04598"]
last_reviewed: "2026-01-22"
---
import Claim from "../../components/Claim.astro";

## What's emerging

<Claim evidence={["1803.01422", "2305.10032", "2406.04598"]}>
  Scale pressures are pushing causal discovery beyond small observational graphs into partially observed systems.
</Claim>

## What's still missing

- Reliable identification under latent confounding at scale.
- Standardized benchmarks with interventions.

<Claim evidence={["1705.08821", "1501.01332", "1907.02893"]} type="Warning">
  Many large-scale discovery claims rely on assumptions that are hard to test in practice.
</Claim>

## Signals to watch

- Methods that incorporate weak supervision or interventional cues.
- Tooling for scalable graph search and validation.

## Related topics / trails

- Identifiability and do-calculus
- Latent confounding

## Guardrails

- What this does NOT prove: Emerging signals are not guarantees of impact.
- Common misstatements: Avoid claiming deployment readiness without evidence-backed evaluation.

