---
title: "Counterfactual Reasoning"
scope: "Counterfactual queries, potential outcomes, and intervention-specific explanations."
anchors:
  - "1705.08821"
  - "1907.02893"
last_reviewed: "2026-01-22"
reading_path:
  beginner:
    - "1705.08821"
  intermediate:
    - "1907.02893"
  advanced:
    - "1803.01422"
---
import Claim from "../../components/Claim.astro";

## Field guide

<Claim evidence={["1705.08821", "1907.02893"]}>
  Counterfactual Reasoning focuses on counterfactual queries, potential outcomes, and intervention-specific explanations, and relies on explicit assumptions before interpreting effects.
</Claim>

<Claim evidence={["1907.02893", "1803.01422"]} type="Signal">
  Recent work in Counterfactual Reasoning emphasizes robustness checks and transparent reporting of causal assumptions.
</Claim>

<Claim evidence={["1705.08821", "1907.02893"]} type="Debate">
  A recurring debate in Counterfactual Reasoning concerns how much identifiability can be claimed without interventions.
</Claim>

## Evaluation cues

<Claim evidence={["1907.02893", "1803.01422"]} type="Metric">
  Evaluation often uses synthetic interventions or held-out environments, which can miss deployment shifts in Counterfactual Reasoning.
</Claim>

## Open problems

<Claim evidence={["1705.08821", "1907.02893"]} type="Open Question">
  Open question: which minimal assumptions are sufficient to estimate effects in Counterfactual Reasoning under realistic data constraints?
</Claim>

## Common pitfalls / Do not overclaim

<Claim evidence={["1705.08821", "1907.02893"]} type="Warning">
  Pitfall: treating predictive accuracy as evidence of causal validity within Counterfactual Reasoning.
</Claim>

## Guardrails

- What this does NOT prove: Correlation alone is not evidence of intervention effects in Counterfactual Reasoning.
- Common misstatements: Avoid claiming causal impact without stating the estimand, assumptions, and sensitivity checks.
