<!DOCTYPE html><html lang="en" data-theme=""> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="Causal prompts, counterfactual reasoning, and evaluation for large language models."><meta name="author" content="Gabriel Saco"><meta property="og:type" content="website"><meta property="og:title" content="Causal Reasoning in LLMs - Causal AI Futures"><meta property="og:description" content="Causal prompts, counterfactual reasoning, and evaluation for large language models."><meta property="og:url" content="https://gsaco.github.io/Causal-AI/Causal-AI/topics/causal-llms/"><meta property="og:site_name" content="Causal AI Futures"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Causal Reasoning in LLMs - Causal AI Futures"><meta name="twitter:description" content="Causal prompts, counterfactual reasoning, and evaluation for large language models."><link rel="canonical" href="https://gsaco.github.io/Causal-AI/Causal-AI/topics/causal-llms/"><link rel="icon" href="/Causal-AI/favicon.svg"><title>Causal Reasoning in LLMs - Causal AI Futures</title><script>
      const storedTheme = localStorage.getItem("theme");
      const prefersDark = window.matchMedia("(prefers-color-scheme: dark)").matches;
      const theme = storedTheme ?? (prefersDark ? "dark" : "light");
      document.documentElement.dataset.theme = theme;
    </script><link rel="stylesheet" href="/Causal-AI/_astro/_slug_.Ctk02bym.css">
<style>h1[data-astro-cid-fz5pa65a]{margin:0 0 .6rem;font-size:clamp(2rem,3vw,2.8rem)}.doc-layout[data-astro-cid-fz5pa65a]{display:grid;grid-template-columns:minmax(0,2.5fr) minmax(240px,1fr);gap:1.5rem;align-items:start}.doc-content[data-astro-cid-fz5pa65a]{display:grid;gap:1.5rem}.doc-aside[data-astro-cid-fz5pa65a] ul[data-astro-cid-fz5pa65a]{padding-left:1.2rem;line-height:1.6}.trail-stack[data-astro-cid-fz5pa65a]{display:grid;gap:1rem}.trail-block[data-astro-cid-fz5pa65a] h3[data-astro-cid-fz5pa65a]{margin:0 0 .8rem}@media (max-width: 900px){.doc-layout[data-astro-cid-fz5pa65a]{grid-template-columns:1fr}}
.paper-card[data-astro-cid-saq65afh] h3[data-astro-cid-saq65afh]{margin:0 0 .35rem;font-size:1.1rem}.abstract[data-astro-cid-saq65afh]{font-family:var(--font-serif);color:var(--muted);line-height:1.6}.meta[data-astro-cid-saq65afh]{display:flex;flex-wrap:wrap;gap:.5rem;margin-top:.8rem}
.provenance[data-astro-cid-bysbcqd4]{border:1px solid var(--border);border-radius:16px;padding:1rem 1.2rem;background:var(--surface)}.provenance[data-astro-cid-bysbcqd4] h3[data-astro-cid-bysbcqd4]{margin:0 0 .8rem;font-size:1rem}.rows[data-astro-cid-bysbcqd4]{display:grid;gap:.6rem}.rows[data-astro-cid-bysbcqd4] div[data-astro-cid-bysbcqd4]{display:grid;gap:.2rem}.rows[data-astro-cid-bysbcqd4] span[data-astro-cid-bysbcqd4]{font-size:.75rem;text-transform:uppercase;letter-spacing:.08em;color:var(--muted)}.rows[data-astro-cid-bysbcqd4] strong[data-astro-cid-bysbcqd4]{font-size:.95rem}.provenance-link[data-astro-cid-bysbcqd4]{display:inline-flex;margin-top:.8rem;font-size:.85rem}
.trail-head[data-astro-cid-3ecx4tpp]{display:grid;gap:.4rem}.trail-steps[data-astro-cid-3ecx4tpp]{list-style:none;padding:0;margin:1.2rem 0 0;display:grid;gap:1rem}.trail-steps[data-astro-cid-3ecx4tpp] li[data-astro-cid-3ecx4tpp]{display:grid;grid-template-columns:auto 1fr;gap:1rem;align-items:start}.step-index[data-astro-cid-3ecx4tpp]{width:32px;height:32px;border-radius:50%;background:var(--surface);border:1px solid var(--border);display:grid;place-items:center;font-weight:600}
.topic-grid[data-astro-cid-zyo4bjwi]{display:grid;gap:1.5rem;grid-template-columns:minmax(0,2fr) minmax(260px,1fr)}.reading[data-astro-cid-zyo4bjwi]{display:grid;gap:1rem;align-content:start}.reading-block[data-astro-cid-zyo4bjwi] ul[data-astro-cid-zyo4bjwi]{margin:.4rem 0 0;padding-left:1.2rem}.grid[data-astro-cid-zyo4bjwi]{display:grid;gap:1.5rem;grid-template-columns:repeat(auto-fit,minmax(260px,1fr))}.subhead[data-astro-cid-zyo4bjwi]{margin-top:2rem}@media (max-width: 900px){.topic-grid[data-astro-cid-zyo4bjwi]{grid-template-columns:1fr}}
</style><style>.citation[data-astro-cid-vpb3wxxj]{position:relative}.citation[data-astro-cid-vpb3wxxj] summary[data-astro-cid-vpb3wxxj]{list-style:none;cursor:pointer}.citation[data-astro-cid-vpb3wxxj] summary[data-astro-cid-vpb3wxxj]::-webkit-details-marker{display:none}.citation-panel[data-astro-cid-vpb3wxxj]{position:absolute;top:2.2rem;left:0;background:var(--bg-elevated);border:1px solid var(--border);border-radius:12px;padding:.75rem;min-width:260px;display:grid;gap:.75rem;box-shadow:0 12px 24px -18px var(--shadow);z-index:5}.citation-item[data-astro-cid-vpb3wxxj]{display:grid;gap:.6rem;padding-bottom:.6rem;border-bottom:1px solid var(--border)}.citation-item[data-astro-cid-vpb3wxxj]:last-child{border-bottom:none;padding-bottom:0}.citation-meta[data-astro-cid-vpb3wxxj]{display:grid;gap:.2rem;font-size:.85rem}.citation-actions[data-astro-cid-vpb3wxxj]{display:flex;flex-wrap:wrap;gap:.4rem}
</style><style>.claim[data-astro-cid-sbzmajdw]{border:1px solid var(--border);border-radius:14px;padding:1rem 1.2rem;background:var(--bg-elevated);display:grid;gap:.75rem}.claim-head[data-astro-cid-sbzmajdw]{display:flex;justify-content:space-between;align-items:center;gap:.6rem;flex-wrap:wrap}.claim-body[data-astro-cid-sbzmajdw]{font-family:var(--font-serif);line-height:1.6}
</style></head> <body> <header class="site-header" data-astro-cid-ctg3m53h> <div class="container header-inner" data-astro-cid-ctg3m53h> <a class="logo" href="/Causal-AI/" data-astro-cid-ctg3m53h>Causal AI Futures</a> <details class="mobile-menu" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Menu</summary> <div class="mobile-panel" data-astro-cid-ctg3m53h> <div class="mobile-group" data-astro-cid-ctg3m53h> <span data-astro-cid-ctg3m53h>Explore</span> <a href="/Causal-AI/observatory" data-astro-cid-ctg3m53h>Observatory</a><a href="/Causal-AI/trends" data-astro-cid-ctg3m53h>Tendencies</a><a href="/Causal-AI/topics" data-astro-cid-ctg3m53h>Topics</a><a href="/Causal-AI/atlas" data-astro-cid-ctg3m53h>Atlas</a><a href="/Causal-AI/papers" data-astro-cid-ctg3m53h>Papers</a> </div><div class="mobile-group" data-astro-cid-ctg3m53h> <span data-astro-cid-ctg3m53h>Learn</span> <a href="/Causal-AI/learn" data-astro-cid-ctg3m53h>Start Here</a><a href="/Causal-AI/learn#playlists" data-astro-cid-ctg3m53h>Playlists</a><a href="/Causal-AI/frontiers" data-astro-cid-ctg3m53h>Frontiers</a><a href="/Causal-AI/glossary" data-astro-cid-ctg3m53h>Glossary</a> </div><div class="mobile-group" data-astro-cid-ctg3m53h> <span data-astro-cid-ctg3m53h>Practice</span> <a href="/Causal-AI/applications" data-astro-cid-ctg3m53h>Applications</a><a href="/Causal-AI/tools" data-astro-cid-ctg3m53h>Tools</a><a href="/Causal-AI/benchmarks" data-astro-cid-ctg3m53h>Benchmarks</a> </div> <div class="mobile-trust" data-astro-cid-ctg3m53h> <span data-astro-cid-ctg3m53h>Trust</span> <a href="/Causal-AI/trust/editorial" data-astro-cid-ctg3m53h>Editorial Policy</a><a href="/Causal-AI/trust/provenance" data-astro-cid-ctg3m53h>Data Provenance</a><a href="/Causal-AI/trust/update-log" data-astro-cid-ctg3m53h>Update Log</a><a href="/Causal-AI/trust/ranking" data-astro-cid-ctg3m53h>Ranking Methodology</a><a href="/Causal-AI/trust/citation-coverage" data-astro-cid-ctg3m53h>Citation Coverage</a><a href="/Causal-AI/trust/how-to-cite" data-astro-cid-ctg3m53h>How to Cite</a> </div> <a href="/Causal-AI/contribute" data-astro-cid-ctg3m53h>Contribute</a> </div> </details> <nav class="nav-links" aria-label="Primary" data-astro-cid-ctg3m53h> <details class="nav-group" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Explore</summary> <div class="nav-panel" data-astro-cid-ctg3m53h> <a href="/Causal-AI/observatory" data-astro-cid-ctg3m53h>Observatory</a><a href="/Causal-AI/trends" data-astro-cid-ctg3m53h>Tendencies</a><a href="/Causal-AI/topics" data-astro-cid-ctg3m53h>Topics</a><a href="/Causal-AI/atlas" data-astro-cid-ctg3m53h>Atlas</a><a href="/Causal-AI/papers" data-astro-cid-ctg3m53h>Papers</a> </div> </details><details class="nav-group" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Learn</summary> <div class="nav-panel" data-astro-cid-ctg3m53h> <a href="/Causal-AI/learn" data-astro-cid-ctg3m53h>Start Here</a><a href="/Causal-AI/learn#playlists" data-astro-cid-ctg3m53h>Playlists</a><a href="/Causal-AI/frontiers" data-astro-cid-ctg3m53h>Frontiers</a><a href="/Causal-AI/glossary" data-astro-cid-ctg3m53h>Glossary</a> </div> </details><details class="nav-group" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Practice</summary> <div class="nav-panel" data-astro-cid-ctg3m53h> <a href="/Causal-AI/applications" data-astro-cid-ctg3m53h>Applications</a><a href="/Causal-AI/tools" data-astro-cid-ctg3m53h>Tools</a><a href="/Causal-AI/benchmarks" data-astro-cid-ctg3m53h>Benchmarks</a> </div> </details> <details class="trust-menu" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Trust</summary> <div class="trust-panel" data-astro-cid-ctg3m53h> <a href="/Causal-AI/trust/editorial" data-astro-cid-ctg3m53h>Editorial Policy</a><a href="/Causal-AI/trust/provenance" data-astro-cid-ctg3m53h>Data Provenance</a><a href="/Causal-AI/trust/update-log" data-astro-cid-ctg3m53h>Update Log</a><a href="/Causal-AI/trust/ranking" data-astro-cid-ctg3m53h>Ranking Methodology</a><a href="/Causal-AI/trust/citation-coverage" data-astro-cid-ctg3m53h>Citation Coverage</a><a href="/Causal-AI/trust/how-to-cite" data-astro-cid-ctg3m53h>How to Cite</a> </div> </details> <a href="/Causal-AI/contribute" data-astro-cid-ctg3m53h>Contribute</a> </nav> <div class="actions" data-astro-cid-ctg3m53h> <button class="button ghost cmdk-trigger" type="button" data-cmdk-open data-astro-cid-ctg3m53h>
Search <span class="kbd" data-astro-cid-ctg3m53h>Cmd+K</span> </button> <button class="button secondary" type="button" aria-label="Toggle theme" data-theme-toggle data-astro-cid-x3pjskd3> <span aria-hidden="true" data-astro-cid-x3pjskd3>O</span> <span class="hide-on-mobile" data-astro-cid-x3pjskd3>Theme</span> </button>  </div> </div> </header>  <main class="">  <section class="section hero" data-astro-cid-fz5pa65a> <div class="container" data-astro-cid-fz5pa65a> <h1 data-astro-cid-fz5pa65a>Causal Reasoning in LLMs - Causal AI Futures</h1> <p class="subtle" data-astro-cid-fz5pa65a>Causal prompts, counterfactual reasoning, and evaluation for large language models.</p> </div> </section> <section class="section" data-astro-cid-fz5pa65a> <div class="container doc-layout" data-astro-cid-fz5pa65a> <article class="doc-content card" data-astro-cid-fz5pa65a>  <span data-pagefind-filter="type:topic" hidden data-astro-cid-zyo4bjwi></span> <span data-pagefind-filter="topic:causal-llms" hidden data-astro-cid-zyo4bjwi></span> <span data-pagefind-meta="type" hidden data-astro-cid-zyo4bjwi>topic</span> <span data-pagefind-meta="title" hidden data-astro-cid-zyo4bjwi>Causal Reasoning in LLMs</span> <section class="topic-grid" data-astro-cid-zyo4bjwi> <div class="card" data-astro-cid-zyo4bjwi> <h2 data-astro-cid-zyo4bjwi>Field guide</h2> <h2 id="field-guide">Field guide</h2>
<div class="claim" data-astro-cid-sbzmajdw> <div class="claim-head" data-astro-cid-sbzmajdw> <span class="chip" data-astro-cid-sbzmajdw>Claim</span> <details class="citation" data-astro-cid-vpb3wxxj> <summary class="chip secondary" data-astro-cid-vpb3wxxj>Evidence (2)</summary> <div class="citation-panel" data-astro-cid-vpb3wxxj> <div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>2307.16405</strong> <span class="subtle" data-astro-cid-vpb3wxxj> 2307.16405  </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/2307.16405" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/2307.16405.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:2307.16405,\n  eprint={2307.16405},\n  archivePrefix={arXiv}\n}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>DAGs with NO TEARS: Continuous Optimization for Structure Learning</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Xun Zheng, Bryan Aragam  - 2018 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1803.01422.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1803.01422,
  title={DAGs with NO TEARS: Continuous Optimization for Structure Learning},
  author={Xun Zheng and Bryan Aragam and Pradeep Ravikumar and Eric Xing},
  year={2018},
  eprint={1803.01422},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div> </div> </details> <script>
  document.querySelectorAll(\"[data-copy-bibtex]\").forEach((button) => {\n    button.addEventListener(\"click\", async () => {\n      const value = button.getAttribute(\"data-copy-bibtex\");\n      if (!value) return;\n      try {\n        await navigator.clipboard.writeText(value);\n        button.textContent = \"Copied\";\n        setTimeout(() => (button.textContent = \"Copy BibTeX\"), 1500);\n      } catch (error) {\n        console.error(error);\n      }\n    });\n  });\n+</script>  </div> <div class="claim-body" data-astro-cid-sbzmajdw> <p>Causal Reasoning in LLMs focuses on causal prompts, counterfactual reasoning, and evaluation for large language models, and relies on explicit assumptions before interpreting effects.</p> </div> </div> 
<div class="claim" data-astro-cid-sbzmajdw> <div class="claim-head" data-astro-cid-sbzmajdw> <span class="chip" data-astro-cid-sbzmajdw>Signal</span> <details class="citation" data-astro-cid-vpb3wxxj> <summary class="chip secondary" data-astro-cid-vpb3wxxj>Evidence (2)</summary> <div class="citation-panel" data-astro-cid-vpb3wxxj> <div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>DAGs with NO TEARS: Continuous Optimization for Structure Learning</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Xun Zheng, Bryan Aragam  - 2018 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1803.01422.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1803.01422,
  title={DAGs with NO TEARS: Continuous Optimization for Structure Learning},
  author={Xun Zheng and Bryan Aragam and Pradeep Ravikumar and Eric Xing},
  year={2018},
  eprint={1803.01422},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>Invariant Risk Minimization</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Martin Arjovsky, Leon Bottou  - 2019 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1907.02893" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1907.02893.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1907.02893,
  title={Invariant Risk Minimization},
  author={Martin Arjovsky and Leon Bottou and Ishaan Gulrajani and David Lopez-Paz},
  year={2019},
  eprint={1907.02893},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div> </div> </details> <script>
  document.querySelectorAll(\"[data-copy-bibtex]\").forEach((button) => {\n    button.addEventListener(\"click\", async () => {\n      const value = button.getAttribute(\"data-copy-bibtex\");\n      if (!value) return;\n      try {\n        await navigator.clipboard.writeText(value);\n        button.textContent = \"Copied\";\n        setTimeout(() => (button.textContent = \"Copy BibTeX\"), 1500);\n      } catch (error) {\n        console.error(error);\n      }\n    });\n  });\n+</script>  </div> <div class="claim-body" data-astro-cid-sbzmajdw> <p>Recent work in Causal Reasoning in LLMs emphasizes robustness checks and transparent reporting of causal assumptions.</p> </div> </div> 
<div class="claim" data-astro-cid-sbzmajdw> <div class="claim-head" data-astro-cid-sbzmajdw> <span class="chip" data-astro-cid-sbzmajdw>Debate</span> <details class="citation" data-astro-cid-vpb3wxxj> <summary class="chip secondary" data-astro-cid-vpb3wxxj>Evidence (2)</summary> <div class="citation-panel" data-astro-cid-vpb3wxxj> <div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>2307.16405</strong> <span class="subtle" data-astro-cid-vpb3wxxj> 2307.16405  </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/2307.16405" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/2307.16405.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:2307.16405,\n  eprint={2307.16405},\n  archivePrefix={arXiv}\n}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>DAGs with NO TEARS: Continuous Optimization for Structure Learning</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Xun Zheng, Bryan Aragam  - 2018 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1803.01422.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1803.01422,
  title={DAGs with NO TEARS: Continuous Optimization for Structure Learning},
  author={Xun Zheng and Bryan Aragam and Pradeep Ravikumar and Eric Xing},
  year={2018},
  eprint={1803.01422},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div> </div> </details> <script>
  document.querySelectorAll(\"[data-copy-bibtex]\").forEach((button) => {\n    button.addEventListener(\"click\", async () => {\n      const value = button.getAttribute(\"data-copy-bibtex\");\n      if (!value) return;\n      try {\n        await navigator.clipboard.writeText(value);\n        button.textContent = \"Copied\";\n        setTimeout(() => (button.textContent = \"Copy BibTeX\"), 1500);\n      } catch (error) {\n        console.error(error);\n      }\n    });\n  });\n+</script>  </div> <div class="claim-body" data-astro-cid-sbzmajdw> <p>A recurring debate in Causal Reasoning in LLMs concerns how much identifiability can be claimed without interventions.</p> </div> </div> 
<h2 id="evaluation-cues">Evaluation cues</h2>
<div class="claim" data-astro-cid-sbzmajdw> <div class="claim-head" data-astro-cid-sbzmajdw> <span class="chip" data-astro-cid-sbzmajdw>Metric</span> <details class="citation" data-astro-cid-vpb3wxxj> <summary class="chip secondary" data-astro-cid-vpb3wxxj>Evidence (2)</summary> <div class="citation-panel" data-astro-cid-vpb3wxxj> <div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>DAGs with NO TEARS: Continuous Optimization for Structure Learning</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Xun Zheng, Bryan Aragam  - 2018 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1803.01422.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1803.01422,
  title={DAGs with NO TEARS: Continuous Optimization for Structure Learning},
  author={Xun Zheng and Bryan Aragam and Pradeep Ravikumar and Eric Xing},
  year={2018},
  eprint={1803.01422},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>Invariant Risk Minimization</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Martin Arjovsky, Leon Bottou  - 2019 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1907.02893" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1907.02893.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1907.02893,
  title={Invariant Risk Minimization},
  author={Martin Arjovsky and Leon Bottou and Ishaan Gulrajani and David Lopez-Paz},
  year={2019},
  eprint={1907.02893},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div> </div> </details> <script>
  document.querySelectorAll(\"[data-copy-bibtex]\").forEach((button) => {\n    button.addEventListener(\"click\", async () => {\n      const value = button.getAttribute(\"data-copy-bibtex\");\n      if (!value) return;\n      try {\n        await navigator.clipboard.writeText(value);\n        button.textContent = \"Copied\";\n        setTimeout(() => (button.textContent = \"Copy BibTeX\"), 1500);\n      } catch (error) {\n        console.error(error);\n      }\n    });\n  });\n+</script>  </div> <div class="claim-body" data-astro-cid-sbzmajdw> <p>Evaluation often uses synthetic interventions or held-out environments, which can miss deployment shifts in Causal Reasoning in LLMs.</p> </div> </div> 
<h2 id="open-problems">Open problems</h2>
<div class="claim" data-astro-cid-sbzmajdw> <div class="claim-head" data-astro-cid-sbzmajdw> <span class="chip" data-astro-cid-sbzmajdw>Open Question</span> <details class="citation" data-astro-cid-vpb3wxxj> <summary class="chip secondary" data-astro-cid-vpb3wxxj>Evidence (2)</summary> <div class="citation-panel" data-astro-cid-vpb3wxxj> <div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>2307.16405</strong> <span class="subtle" data-astro-cid-vpb3wxxj> 2307.16405  </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/2307.16405" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/2307.16405.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:2307.16405,\n  eprint={2307.16405},\n  archivePrefix={arXiv}\n}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>DAGs with NO TEARS: Continuous Optimization for Structure Learning</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Xun Zheng, Bryan Aragam  - 2018 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1803.01422.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1803.01422,
  title={DAGs with NO TEARS: Continuous Optimization for Structure Learning},
  author={Xun Zheng and Bryan Aragam and Pradeep Ravikumar and Eric Xing},
  year={2018},
  eprint={1803.01422},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div> </div> </details> <script>
  document.querySelectorAll(\"[data-copy-bibtex]\").forEach((button) => {\n    button.addEventListener(\"click\", async () => {\n      const value = button.getAttribute(\"data-copy-bibtex\");\n      if (!value) return;\n      try {\n        await navigator.clipboard.writeText(value);\n        button.textContent = \"Copied\";\n        setTimeout(() => (button.textContent = \"Copy BibTeX\"), 1500);\n      } catch (error) {\n        console.error(error);\n      }\n    });\n  });\n+</script>  </div> <div class="claim-body" data-astro-cid-sbzmajdw> <p>Open question: which minimal assumptions are sufficient to estimate effects in Causal Reasoning in LLMs under realistic data constraints?</p> </div> </div> 
<h2 id="common-pitfalls--do-not-overclaim">Common pitfalls / Do not overclaim</h2>
<div class="claim" data-astro-cid-sbzmajdw> <div class="claim-head" data-astro-cid-sbzmajdw> <span class="chip" data-astro-cid-sbzmajdw>Warning</span> <details class="citation" data-astro-cid-vpb3wxxj> <summary class="chip secondary" data-astro-cid-vpb3wxxj>Evidence (2)</summary> <div class="citation-panel" data-astro-cid-vpb3wxxj> <div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>2307.16405</strong> <span class="subtle" data-astro-cid-vpb3wxxj> 2307.16405  </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/2307.16405" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/2307.16405.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:2307.16405,\n  eprint={2307.16405},\n  archivePrefix={arXiv}\n}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>DAGs with NO TEARS: Continuous Optimization for Structure Learning</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Xun Zheng, Bryan Aragam  - 2018 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1803.01422.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1803.01422,
  title={DAGs with NO TEARS: Continuous Optimization for Structure Learning},
  author={Xun Zheng and Bryan Aragam and Pradeep Ravikumar and Eric Xing},
  year={2018},
  eprint={1803.01422},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div> </div> </details> <script>
  document.querySelectorAll(\"[data-copy-bibtex]\").forEach((button) => {\n    button.addEventListener(\"click\", async () => {\n      const value = button.getAttribute(\"data-copy-bibtex\");\n      if (!value) return;\n      try {\n        await navigator.clipboard.writeText(value);\n        button.textContent = \"Copied\";\n        setTimeout(() => (button.textContent = \"Copy BibTeX\"), 1500);\n      } catch (error) {\n        console.error(error);\n      }\n    });\n  });\n+</script>  </div> <div class="claim-body" data-astro-cid-sbzmajdw> <p>Pitfall: treating predictive accuracy as evidence of causal validity within Causal Reasoning in LLMs.</p> </div> </div> 
<h2 id="guardrails">Guardrails</h2>
<ul>
<li>What this does NOT prove: Correlation alone is not evidence of intervention effects in Causal Reasoning in LLMs.</li>
<li>Common misstatements: Avoid claiming causal impact without stating the estimand, assumptions, and sensitivity checks.</li>
</ul> </div> <aside class="card reading" data-astro-cid-zyo4bjwi> <h3 data-astro-cid-zyo4bjwi>Reading path</h3> <div class="reading-block" data-astro-cid-zyo4bjwi> <strong data-astro-cid-zyo4bjwi>Beginner</strong> <ul data-astro-cid-zyo4bjwi> <li data-astro-cid-zyo4bjwi><a href="https://arxiv.org/abs/2307.16405" target="_blank" rel="noreferrer" data-astro-cid-zyo4bjwi>2307.16405</a></li> </ul> </div> <div class="reading-block" data-astro-cid-zyo4bjwi> <strong data-astro-cid-zyo4bjwi>Intermediate</strong> <ul data-astro-cid-zyo4bjwi> <li data-astro-cid-zyo4bjwi><a href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer" data-astro-cid-zyo4bjwi>1803.01422</a></li> </ul> </div> <div class="reading-block" data-astro-cid-zyo4bjwi> <strong data-astro-cid-zyo4bjwi>Advanced</strong> <ul data-astro-cid-zyo4bjwi> <li data-astro-cid-zyo4bjwi><a href="https://arxiv.org/abs/1907.02893" target="_blank" rel="noreferrer" data-astro-cid-zyo4bjwi>1907.02893</a></li> </ul> </div> </aside> </section> <section class="card" data-astro-cid-zyo4bjwi> <h2 data-astro-cid-zyo4bjwi>Snapshot provenance</h2> <aside class="provenance" data-astro-cid-bysbcqd4> <h3 data-astro-cid-bysbcqd4>Provenance</h3> <div class="rows" data-astro-cid-bysbcqd4> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Snapshot</span> <strong data-astro-cid-bysbcqd4>2026-01-22</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Harvest window</span> <strong data-astro-cid-bysbcqd4>2025-12-23 to 2026-01-21</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Harvest source</span> <strong data-astro-cid-bysbcqd4>arxiv_api</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Last updated</span> <strong data-astro-cid-bysbcqd4>2026-01-22T02:10:00Z</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Ranking config</span> <strong data-astro-cid-bysbcqd4>2026-01-22/v1</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Query pack</span> <strong data-astro-cid-bysbcqd4>2026-01-22/v1</strong> </div> </div> <a class="subtle provenance-link" href="/Causal-AI/trust/update-log" data-astro-cid-bysbcqd4>View update log</a> </aside>  </section> <section data-astro-cid-zyo4bjwi> <h2 data-astro-cid-zyo4bjwi>What's new in this topic</h2> <div class="grid" data-astro-cid-zyo4bjwi> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1803.01422" data-astro-cid-saq65afh>DAGs with NO TEARS: Continuous Optimization for Structure Learning</a></h3> <div class="subtle" data-astro-cid-saq65afh>Xun Zheng, Bryan Aragam, Pradeep Ravikumar +1</div> </div> <p class="abstract" data-astro-cid-saq65afh>A continuous optimization approach to learning directed acyclic graphs that replaces combinatorial search with a smooth constraint.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer">arXiv:1803.01422</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2018-06-12</span> <span class="chip" data-astro-cid-saq65afh>v2</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>causal-discovery</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1907.02893" data-astro-cid-saq65afh>Invariant Risk Minimization</a></h3> <div class="subtle" data-astro-cid-saq65afh>Martin Arjovsky, Leon Bottou, Ishaan Gulrajani +1</div> </div> <p class="abstract" data-astro-cid-saq65afh>A principle for learning predictors that are stable across environments by enforcing invariance of optimal classifiers.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1907.02893" target="_blank" rel="noreferrer">arXiv:1907.02893</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2020-02-12</span> <span class="chip" data-astro-cid-saq65afh>v3</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>distribution-shift</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1703.06856" data-astro-cid-saq65afh>Counterfactual Fairness</a></h3> <div class="subtle" data-astro-cid-saq65afh>Matt J. Kusner, Joshua Loftus, Chris Russell +1</div> </div> <p class="abstract" data-astro-cid-saq65afh>A causal definition of fairness based on comparing decisions across counterfactual worlds where protected attributes differ.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1703.06856" target="_blank" rel="noreferrer">arXiv:1703.06856</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2018-03-12</span> <span class="chip" data-astro-cid-saq65afh>v2</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>causal-fairness</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1705.08821" data-astro-cid-saq65afh>Causal Effect Inference with Deep Latent-Variable Models</a></h3> <div class="subtle" data-astro-cid-saq65afh>Yarin Gal, Ricardo Silva</div> </div> <p class="abstract" data-astro-cid-saq65afh>A deep latent-variable model (CEVAE) for causal effect inference with hidden confounding using variational methods.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1705.08821" target="_blank" rel="noreferrer">arXiv:1705.08821</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2017-10-03</span> <span class="chip" data-astro-cid-saq65afh>v1</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>effect-estimation</span> </div> </article>  </div> <h3 class="subhead" data-astro-cid-zyo4bjwi>Trending</h3> <div class="grid" data-astro-cid-zyo4bjwi> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1803.01422" data-astro-cid-saq65afh>DAGs with NO TEARS: Continuous Optimization for Structure Learning</a></h3> <div class="subtle" data-astro-cid-saq65afh>Xun Zheng, Bryan Aragam, Pradeep Ravikumar +1</div> </div> <p class="abstract" data-astro-cid-saq65afh>A continuous optimization approach to learning directed acyclic graphs that replaces combinatorial search with a smooth constraint.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer">arXiv:1803.01422</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2018-06-12</span> <span class="chip" data-astro-cid-saq65afh>v2</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>causal-discovery</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1907.02893" data-astro-cid-saq65afh>Invariant Risk Minimization</a></h3> <div class="subtle" data-astro-cid-saq65afh>Martin Arjovsky, Leon Bottou, Ishaan Gulrajani +1</div> </div> <p class="abstract" data-astro-cid-saq65afh>A principle for learning predictors that are stable across environments by enforcing invariance of optimal classifiers.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1907.02893" target="_blank" rel="noreferrer">arXiv:1907.02893</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2020-02-12</span> <span class="chip" data-astro-cid-saq65afh>v3</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>distribution-shift</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1703.06856" data-astro-cid-saq65afh>Counterfactual Fairness</a></h3> <div class="subtle" data-astro-cid-saq65afh>Matt J. Kusner, Joshua Loftus, Chris Russell +1</div> </div> <p class="abstract" data-astro-cid-saq65afh>A causal definition of fairness based on comparing decisions across counterfactual worlds where protected attributes differ.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1703.06856" target="_blank" rel="noreferrer">arXiv:1703.06856</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2018-03-12</span> <span class="chip" data-astro-cid-saq65afh>v2</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>causal-fairness</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1705.08821" data-astro-cid-saq65afh>Causal Effect Inference with Deep Latent-Variable Models</a></h3> <div class="subtle" data-astro-cid-saq65afh>Yarin Gal, Ricardo Silva</div> </div> <p class="abstract" data-astro-cid-saq65afh>A deep latent-variable model (CEVAE) for causal effect inference with hidden confounding using variational methods.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1705.08821" target="_blank" rel="noreferrer">arXiv:1705.08821</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2017-10-03</span> <span class="chip" data-astro-cid-saq65afh>v1</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>effect-estimation</span> </div> </article>  </div> </section> <section class="section continue"> <div class="container"> <div class="section-header"> <p class="eyebrow">Continue exploring</p> <h2>Follow the trail</h2> <p>Jump to a related topic, tendency, or a curated paper trail.</p> </div> <div class="card-grid"> <a class="card" href="/Causal-AI/topics/causal-agents"> <h3>Causal Agents</h3> <p class="subtle">Agentic systems that plan interventions or tool use with causal models.</p> </a> <a class="card" href="/Causal-AI/trends/benchmarks-evaluation-maturity"> <h3>Benchmarks &amp; Evaluation Maturity</h3> <p class="subtle">Causal AI benchmarks are shifting from synthetic tasks to intervention-aware evaluation.</p> </a> <a class="card" href="/Causal-AI/observatory?trail=graphs-to-invariance"> <h3>Graphs to Invariance</h3> <p class="subtle">How structural discovery ideas evolved into robust, invariant prediction strategies.</p> </a> <a class="card callout-card" href="/Causal-AI/observatory?topic=causal-agents"> <h3>Open the Observatory</h3> <p class="subtle">Follow live signals with filters preselected.</p> </a> </div> </div> </section>   </article> <aside class="doc-aside" data-astro-cid-fz5pa65a> <div class="card" data-astro-cid-fz5pa65a> <h3 data-astro-cid-fz5pa65a>On this page</h3> <ul data-astro-cid-fz5pa65a> <li data-astro-cid-fz5pa65a><a href="#field-guide" data-astro-cid-fz5pa65a>Field guide</a></li><li data-astro-cid-fz5pa65a><a href="#evaluation-cues" data-astro-cid-fz5pa65a>Evaluation cues</a></li><li data-astro-cid-fz5pa65a><a href="#open-problems" data-astro-cid-fz5pa65a>Open problems</a></li><li data-astro-cid-fz5pa65a><a href="#common-pitfalls--do-not-overclaim" data-astro-cid-fz5pa65a>Common pitfalls / Do not overclaim</a></li><li data-astro-cid-fz5pa65a><a href="#guardrails" data-astro-cid-fz5pa65a>Guardrails</a></li> </ul> </div> <div class="card" data-astro-cid-fz5pa65a> <h3 data-astro-cid-fz5pa65a>Evidence summary</h3> <div class="tag-row" data-astro-cid-fz5pa65a> <a class="chip" href="https://arxiv.org/abs/2307.16405" target="_blank" rel="noreferrer">arXiv:2307.16405</a> </div> </div>  </aside> </div> </section>   </main> <footer class="site-footer" data-astro-cid-gcn2mc3v> <div class="container footer-inner" data-astro-cid-gcn2mc3v> <div class="footer-brand" data-astro-cid-gcn2mc3v> <strong data-astro-cid-gcn2mc3v>Causal AI Futures</strong> <p class="subtle" data-astro-cid-gcn2mc3v>A field guide to the intervention era.</p> <p class="subtle footer-credit" data-astro-cid-gcn2mc3v>Built by Gabriel Saco.</p> </div> <div class="footer-links" data-astro-cid-gcn2mc3v> <a href="/Causal-AI/about" data-astro-cid-gcn2mc3v>About</a><a href="https://github.com/gsaco/Causal-AI" target="_blank" rel="noreferrer" data-astro-cid-gcn2mc3v>GitHub</a><a href="/Causal-AI/trust/how-to-cite" data-astro-cid-gcn2mc3v>Cite</a> </div> </div> </footer>  <div class="cmdk" data-cmdk hidden data-astro-cid-wozhyvwc> <div class="cmdk-backdrop" data-cmdk-close data-astro-cid-wozhyvwc></div> <div class="cmdk-panel" role="dialog" aria-modal="true" aria-label="Command palette" data-astro-cid-wozhyvwc> <div class="cmdk-header" data-astro-cid-wozhyvwc> <input type="search" placeholder="Search papers, topics, and tendencies" data-cmdk-input data-astro-cid-wozhyvwc> <div class="cmdk-hint" data-astro-cid-wozhyvwc> <span class="kbd" data-astro-cid-wozhyvwc>Esc</span> to close
</div> </div> <div class="cmdk-results" data-cmdk-results data-astro-cid-wozhyvwc></div> </div> </div> <script src="/Causal-AI/pagefind/pagefind.js" defer></script> <script>
  const palette = document.querySelector("[data-cmdk]");
  const input = document.querySelector("[data-cmdk-input]");
  const results = document.querySelector("[data-cmdk-results]");
  const closeTriggers = document.querySelectorAll("[data-cmdk-close]");
  const openTriggers = document.querySelectorAll("[data-cmdk-open]");

  function openPalette() {
    palette.hidden = false;
    palette.classList.add("open");
    input.focus();
    results.innerHTML = "<p class='subtle'>Type to search the site.</p>";
  }

  function closePalette() {
    palette.classList.remove("open");
    palette.hidden = true;
  }

  closeTriggers.forEach((trigger) => trigger.addEventListener("click", closePalette));
  openTriggers.forEach((trigger) => trigger.addEventListener("click", openPalette));

  document.addEventListener("keydown", (event) => {
    if ((event.metaKey || event.ctrlKey) && event.key.toLowerCase() === "k") {
      event.preventDefault();
      openPalette();
    }
    if (event.key === "Escape" && !palette.hidden) {
      event.preventDefault();
      closePalette();
    }
  });

  palette.addEventListener("keydown", (event) => {
    if (event.key !== "Tab") return;
    const focusable = Array.from(palette.querySelectorAll("input, a, button, [tabindex='0']"))
      .filter((el) => !el.hasAttribute("disabled"));
    if (focusable.length === 0) return;
    const first = focusable[0];
    const last = focusable[focusable.length - 1];
    if (event.shiftKey && document.activeElement === first) {
      event.preventDefault();
      last.focus();
    } else if (!event.shiftKey && document.activeElement === last) {
      event.preventDefault();
      first.focus();
    }
  });

  async function runSearch(query) {
    if (!query) {
      results.innerHTML = "<p class='subtle'>Type to search the site.</p>";
      return;
    }
    if (!window.pagefind) return;
    const search = await window.pagefind.search(query);
    const entries = await Promise.all(search.results.slice(0, 6).map((r) => r.data()));
    results.innerHTML = entries
      .map((entry) => {
        return `
          <a class="cmdk-item" href="${entry.url}">
            <div>
              <strong>${entry.meta.title ?? entry.title}</strong>
              <p>${entry.excerpt}</p>
            </div>
            <span class="chip">${entry.meta.type ?? "result"}</span>
          </a>
        `;
      })
      .join("");
  }

  input.addEventListener("input", (event) => {
    runSearch(event.target.value);
  });

  results.addEventListener("click", (event) => {
    const target = event.target.closest("a");
    if (target) closePalette();
  });
</script>  <script>
      const toggle = document.querySelector("[data-theme-toggle]");
      if (toggle) {
        toggle.addEventListener("click", () => {
          const current = document.documentElement.dataset.theme;
          const next = current === "dark" ? "light" : "dark";
          document.documentElement.dataset.theme = next;
          localStorage.setItem("theme", next);
        });
      }
    </script> </body> </html>