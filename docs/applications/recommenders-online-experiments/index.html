<!DOCTYPE html><html lang="en" data-theme=""> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="Causal evaluation for interventions in personalization, ranking, and product experiments."><meta name="author" content="Gabriel Saco"><meta property="og:type" content="website"><meta property="og:title" content="Recommender Systems &#38; Online Experiments - Applications"><meta property="og:description" content="Causal evaluation for interventions in personalization, ranking, and product experiments."><meta property="og:url" content="https://gsaco.github.io/Causal-AI/Causal-AI/applications/recommenders-online-experiments/"><meta property="og:site_name" content="Causal AI Futures"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Recommender Systems &#38; Online Experiments - Applications"><meta name="twitter:description" content="Causal evaluation for interventions in personalization, ranking, and product experiments."><link rel="canonical" href="https://gsaco.github.io/Causal-AI/Causal-AI/applications/recommenders-online-experiments/"><link rel="icon" href="/Causal-AI/favicon.svg"><title>Recommender Systems &amp; Online Experiments - Applications</title><script>
      const storedTheme = localStorage.getItem("theme");
      const prefersDark = window.matchMedia("(prefers-color-scheme: dark)").matches;
      const theme = storedTheme ?? (prefersDark ? "dark" : "light");
      document.documentElement.dataset.theme = theme;
    </script><link rel="stylesheet" href="/Causal-AI/_astro/_slug_.D7JDIGf2.css">
<style>h1[data-astro-cid-fz5pa65a]{margin:0 0 .6rem;font-size:clamp(2rem,3vw,2.8rem)}.doc-layout[data-astro-cid-fz5pa65a]{display:grid;grid-template-columns:minmax(0,2.5fr) minmax(240px,1fr);gap:1.5rem;align-items:start}.doc-content[data-astro-cid-fz5pa65a]{display:grid;gap:1.5rem}.doc-aside[data-astro-cid-fz5pa65a] ul[data-astro-cid-fz5pa65a]{padding-left:1.2rem;line-height:1.6}.trail-stack[data-astro-cid-fz5pa65a]{display:grid;gap:1rem}.trail-block[data-astro-cid-fz5pa65a] h3[data-astro-cid-fz5pa65a]{margin:0 0 .8rem}@media (max-width: 900px){.doc-layout[data-astro-cid-fz5pa65a]{grid-template-columns:1fr}}
.paper-card[data-astro-cid-saq65afh] h3[data-astro-cid-saq65afh]{margin:0 0 .35rem;font-size:1.1rem}.abstract[data-astro-cid-saq65afh]{font-family:var(--font-serif);color:var(--muted);line-height:1.6}.meta[data-astro-cid-saq65afh]{display:flex;flex-wrap:wrap;gap:.5rem;margin-top:.8rem}
.provenance[data-astro-cid-bysbcqd4]{border:1px solid var(--border);border-radius:16px;padding:1rem 1.2rem;background:var(--surface)}.provenance[data-astro-cid-bysbcqd4] h3[data-astro-cid-bysbcqd4]{margin:0 0 .8rem;font-size:1rem}.rows[data-astro-cid-bysbcqd4]{display:grid;gap:.6rem}.rows[data-astro-cid-bysbcqd4] div[data-astro-cid-bysbcqd4]{display:grid;gap:.2rem}.rows[data-astro-cid-bysbcqd4] span[data-astro-cid-bysbcqd4]{font-size:.75rem;text-transform:uppercase;letter-spacing:.08em;color:var(--muted)}.rows[data-astro-cid-bysbcqd4] strong[data-astro-cid-bysbcqd4]{font-size:.95rem}.provenance-link[data-astro-cid-bysbcqd4]{display:inline-flex;margin-top:.8rem;font-size:.85rem}
.trail-head[data-astro-cid-3ecx4tpp]{display:grid;gap:.4rem}.trail-steps[data-astro-cid-3ecx4tpp]{list-style:none;padding:0;margin:1.2rem 0 0;display:grid;gap:1rem}.trail-steps[data-astro-cid-3ecx4tpp] li[data-astro-cid-3ecx4tpp]{display:grid;grid-template-columns:auto 1fr;gap:1rem;align-items:start}.step-index[data-astro-cid-3ecx4tpp]{width:32px;height:32px;border-radius:50%;background:var(--surface);border:1px solid var(--border);display:grid;place-items:center;font-weight:600}
.grid[data-astro-cid-w2hxe52l]{display:grid;gap:1.5rem;grid-template-columns:repeat(auto-fit,minmax(260px,1fr))}.subhead[data-astro-cid-w2hxe52l]{margin-top:2rem}
</style><style>.citation[data-astro-cid-vpb3wxxj]{position:relative}.citation[data-astro-cid-vpb3wxxj] summary[data-astro-cid-vpb3wxxj]{list-style:none;cursor:pointer}.citation[data-astro-cid-vpb3wxxj] summary[data-astro-cid-vpb3wxxj]::-webkit-details-marker{display:none}.citation-panel[data-astro-cid-vpb3wxxj]{position:absolute;top:2.2rem;left:0;background:var(--bg-elevated);border:1px solid var(--border);border-radius:12px;padding:.75rem;min-width:260px;display:grid;gap:.75rem;box-shadow:0 12px 24px -18px var(--shadow);z-index:5}.citation-item[data-astro-cid-vpb3wxxj]{display:grid;gap:.6rem;padding-bottom:.6rem;border-bottom:1px solid var(--border)}.citation-item[data-astro-cid-vpb3wxxj]:last-child{border-bottom:none;padding-bottom:0}.citation-meta[data-astro-cid-vpb3wxxj]{display:grid;gap:.2rem;font-size:.85rem}.citation-actions[data-astro-cid-vpb3wxxj]{display:flex;flex-wrap:wrap;gap:.4rem}
</style><style>.claim[data-astro-cid-sbzmajdw]{border:1px solid var(--border);border-radius:14px;padding:1rem 1.2rem;background:var(--bg-elevated);display:grid;gap:.75rem}.claim-head[data-astro-cid-sbzmajdw]{display:flex;justify-content:space-between;align-items:center;gap:.6rem;flex-wrap:wrap}.claim-body[data-astro-cid-sbzmajdw]{font-family:var(--font-serif);line-height:1.6}
</style></head> <body> <header class="site-header" data-astro-cid-ctg3m53h> <div class="container header-inner" data-astro-cid-ctg3m53h> <a class="logo" href="/Causal-AI/" data-astro-cid-ctg3m53h>Causal AI Futures</a> <details class="mobile-menu" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Menu</summary> <div class="mobile-panel" data-astro-cid-ctg3m53h> <div class="mobile-group" data-astro-cid-ctg3m53h> <span data-astro-cid-ctg3m53h>Explore</span> <a href="/Causal-AI/observatory" data-astro-cid-ctg3m53h>Observatory</a><a href="/Causal-AI/trends" data-astro-cid-ctg3m53h>Tendencies</a><a href="/Causal-AI/topics" data-astro-cid-ctg3m53h>Topics</a><a href="/Causal-AI/atlas" data-astro-cid-ctg3m53h>Atlas</a><a href="/Causal-AI/papers" data-astro-cid-ctg3m53h>Papers</a> </div><div class="mobile-group" data-astro-cid-ctg3m53h> <span data-astro-cid-ctg3m53h>Learn</span> <a href="/Causal-AI/learn" data-astro-cid-ctg3m53h>Start Here</a><a href="/Causal-AI/learn#playlists" data-astro-cid-ctg3m53h>Playlists</a><a href="/Causal-AI/frontiers" data-astro-cid-ctg3m53h>Frontiers</a><a href="/Causal-AI/glossary" data-astro-cid-ctg3m53h>Glossary</a> </div><div class="mobile-group" data-astro-cid-ctg3m53h> <span data-astro-cid-ctg3m53h>Practice</span> <a href="/Causal-AI/applications" data-astro-cid-ctg3m53h>Applications</a><a href="/Causal-AI/tools" data-astro-cid-ctg3m53h>Tools</a><a href="/Causal-AI/benchmarks" data-astro-cid-ctg3m53h>Benchmarks</a> </div> <div class="mobile-trust" data-astro-cid-ctg3m53h> <span data-astro-cid-ctg3m53h>Trust</span> <a href="/Causal-AI/trust/editorial" data-astro-cid-ctg3m53h>Editorial Policy</a><a href="/Causal-AI/trust/provenance" data-astro-cid-ctg3m53h>Data Provenance</a><a href="/Causal-AI/trust/update-log" data-astro-cid-ctg3m53h>Update Log</a><a href="/Causal-AI/trust/ranking" data-astro-cid-ctg3m53h>Ranking Methodology</a><a href="/Causal-AI/trust/citation-coverage" data-astro-cid-ctg3m53h>Citation Coverage</a><a href="/Causal-AI/trust/how-to-cite" data-astro-cid-ctg3m53h>How to Cite</a> </div> <a href="/Causal-AI/contribute" data-astro-cid-ctg3m53h>Contribute</a> </div> </details> <nav class="nav-links" aria-label="Primary" data-astro-cid-ctg3m53h> <details class="nav-group" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Explore</summary> <div class="nav-panel" data-astro-cid-ctg3m53h> <a href="/Causal-AI/observatory" data-astro-cid-ctg3m53h>Observatory</a><a href="/Causal-AI/trends" data-astro-cid-ctg3m53h>Tendencies</a><a href="/Causal-AI/topics" data-astro-cid-ctg3m53h>Topics</a><a href="/Causal-AI/atlas" data-astro-cid-ctg3m53h>Atlas</a><a href="/Causal-AI/papers" data-astro-cid-ctg3m53h>Papers</a> </div> </details><details class="nav-group" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Learn</summary> <div class="nav-panel" data-astro-cid-ctg3m53h> <a href="/Causal-AI/learn" data-astro-cid-ctg3m53h>Start Here</a><a href="/Causal-AI/learn#playlists" data-astro-cid-ctg3m53h>Playlists</a><a href="/Causal-AI/frontiers" data-astro-cid-ctg3m53h>Frontiers</a><a href="/Causal-AI/glossary" data-astro-cid-ctg3m53h>Glossary</a> </div> </details><details class="nav-group" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Practice</summary> <div class="nav-panel" data-astro-cid-ctg3m53h> <a href="/Causal-AI/applications" data-astro-cid-ctg3m53h>Applications</a><a href="/Causal-AI/tools" data-astro-cid-ctg3m53h>Tools</a><a href="/Causal-AI/benchmarks" data-astro-cid-ctg3m53h>Benchmarks</a> </div> </details> <details class="trust-menu" data-astro-cid-ctg3m53h> <summary data-astro-cid-ctg3m53h>Trust</summary> <div class="trust-panel" data-astro-cid-ctg3m53h> <a href="/Causal-AI/trust/editorial" data-astro-cid-ctg3m53h>Editorial Policy</a><a href="/Causal-AI/trust/provenance" data-astro-cid-ctg3m53h>Data Provenance</a><a href="/Causal-AI/trust/update-log" data-astro-cid-ctg3m53h>Update Log</a><a href="/Causal-AI/trust/ranking" data-astro-cid-ctg3m53h>Ranking Methodology</a><a href="/Causal-AI/trust/citation-coverage" data-astro-cid-ctg3m53h>Citation Coverage</a><a href="/Causal-AI/trust/how-to-cite" data-astro-cid-ctg3m53h>How to Cite</a> </div> </details> <a href="/Causal-AI/contribute" data-astro-cid-ctg3m53h>Contribute</a> </nav> <div class="actions" data-astro-cid-ctg3m53h> <button class="button ghost cmdk-trigger" type="button" data-cmdk-open data-astro-cid-ctg3m53h>
Search <span class="kbd" data-astro-cid-ctg3m53h>Cmd+K</span> </button> <button class="button secondary" type="button" aria-label="Toggle theme" data-theme-toggle data-astro-cid-x3pjskd3> <span aria-hidden="true" data-astro-cid-x3pjskd3>O</span> <span class="hide-on-mobile" data-astro-cid-x3pjskd3>Theme</span> </button>  </div> </div> </header>  <main class="">  <section class="section hero" data-astro-cid-fz5pa65a> <div class="container" data-astro-cid-fz5pa65a> <h1 data-astro-cid-fz5pa65a>Recommender Systems &amp; Online Experiments - Applications</h1> <p class="subtle" data-astro-cid-fz5pa65a>Causal evaluation for interventions in personalization, ranking, and product experiments.</p> </div> </section> <section class="section" data-astro-cid-fz5pa65a> <div class="container doc-layout" data-astro-cid-fz5pa65a> <article class="doc-content card" data-astro-cid-fz5pa65a>  <span data-pagefind-filter="type:application" hidden data-astro-cid-w2hxe52l></span> <span data-pagefind-meta="type" hidden data-astro-cid-w2hxe52l>application</span> <span data-pagefind-meta="title" hidden data-astro-cid-w2hxe52l>Recommender Systems &amp; Online Experiments</span> <section class="card" data-astro-cid-w2hxe52l> <h2 id="the-causal-question">The causal question</h2>
<p>Which interventions improve user outcomes, and how robust are they under feedback loops and non-stationarity?</p>
<h2 id="common-failure-modes-without-causality">Common failure modes without causality</h2>
<ul>
<li>Feedback loops bias logged data.</li>
<li>Short-term metrics hide long-term causal effects.</li>
<li>Offline evaluation fails to predict online impact.</li>
</ul>
<div class="claim" data-astro-cid-sbzmajdw> <div class="claim-head" data-astro-cid-sbzmajdw> <span class="chip" data-astro-cid-sbzmajdw>Claim</span> <details class="citation" data-astro-cid-vpb3wxxj> <summary class="chip secondary" data-astro-cid-vpb3wxxj>Evidence (3)</summary> <div class="citation-panel" data-astro-cid-vpb3wxxj> <div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>Causal Effect Inference with Deep Latent-Variable Models</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Yarin Gal, Ricardo Silva  - 2017 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1705.08821" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1705.08821.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1705.08821,
  title={Causal Effect Inference with Deep Latent-Variable Models},
  author={Yarin Gal and Ricardo Silva},
  year={2017},
  eprint={1705.08821},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>2010.05761</strong> <span class="subtle" data-astro-cid-vpb3wxxj> 2010.05761  </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/2010.05761" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/2010.05761.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:2010.05761,\n  eprint={2010.05761},\n  archivePrefix={arXiv}\n}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>Invariant Risk Minimization</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Martin Arjovsky, Leon Bottou  - 2019 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1907.02893" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1907.02893.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1907.02893,
  title={Invariant Risk Minimization},
  author={Martin Arjovsky and Leon Bottou and Ishaan Gulrajani and David Lopez-Paz},
  year={2019},
  eprint={1907.02893},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div> </div> </details> <script>
  document.querySelectorAll(\"[data-copy-bibtex]\").forEach((button) => {\n    button.addEventListener(\"click\", async () => {\n      const value = button.getAttribute(\"data-copy-bibtex\");\n      if (!value) return;\n      try {\n        await navigator.clipboard.writeText(value);\n        button.textContent = \"Copied\";\n        setTimeout(() => (button.textContent = \"Copy BibTeX\"), 1500);\n      } catch (error) {\n        console.error(error);\n      }\n    });\n  });\n+</script>  </div> <div class="claim-body" data-astro-cid-sbzmajdw> <p>Off-policy evaluation and causal effect estimation are necessary when randomized experiments are limited or costly.</p> </div> </div> 
<h2 id="methods-that-show-up-a-lot">Methods that show up a lot</h2>
<ul>
<li>Off-policy evaluation, counterfactual estimators</li>
<li>Causal bandits and reinforcement learning</li>
<li>Interventional evaluation protocols</li>
</ul>
<div class="claim" data-astro-cid-sbzmajdw> <div class="claim-head" data-astro-cid-sbzmajdw> <span class="chip" data-astro-cid-sbzmajdw>Signal</span> <details class="citation" data-astro-cid-vpb3wxxj> <summary class="chip secondary" data-astro-cid-vpb3wxxj>Evidence (3)</summary> <div class="citation-panel" data-astro-cid-vpb3wxxj> <div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>DAGs with NO TEARS: Continuous Optimization for Structure Learning</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Xun Zheng, Bryan Aragam  - 2018 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/1803.01422.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:1803.01422,
  title={DAGs with NO TEARS: Continuous Optimization for Structure Learning},
  author={Xun Zheng and Bryan Aragam and Pradeep Ravikumar and Eric Xing},
  year={2018},
  eprint={1803.01422},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>DoWhy: An End-to-End Library for Causal Inference</strong> <span class="subtle" data-astro-cid-vpb3wxxj> Amit Sharma, Emre Kiciman  - 2020 </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/2011.04216" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/2011.04216.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:2011.04216,
  title={DoWhy: An End-to-End Library for Causal Inference},
  author={Amit Sharma and Emre Kiciman},
  year={2020},
  eprint={2011.04216},
  archivePrefix={arXiv},
  primaryClass={cs.AI}
}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div><div class="citation-item" data-astro-cid-vpb3wxxj> <div class="citation-meta" data-astro-cid-vpb3wxxj> <strong data-astro-cid-vpb3wxxj>2307.16405</strong> <span class="subtle" data-astro-cid-vpb3wxxj> 2307.16405  </span> </div> <div class="citation-actions" data-astro-cid-vpb3wxxj> <a class="chip" href="https://arxiv.org/abs/2307.16405" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>Abs</a> <a class="chip secondary" href="https://arxiv.org/pdf/2307.16405.pdf" target="_blank" rel="noreferrer" data-astro-cid-vpb3wxxj>PDF</a> <button class="chip ghost" type="button" data-copy-bibtex="@article{arxiv:2307.16405,\n  eprint={2307.16405},\n  archivePrefix={arXiv}\n}" data-astro-cid-vpb3wxxj>Copy BibTeX</button> </div> </div> </div> </details> <script>
  document.querySelectorAll(\"[data-copy-bibtex]\").forEach((button) => {\n    button.addEventListener(\"click\", async () => {\n      const value = button.getAttribute(\"data-copy-bibtex\");\n      if (!value) return;\n      try {\n        await navigator.clipboard.writeText(value);\n        button.textContent = \"Copied\";\n        setTimeout(() => (button.textContent = \"Copy BibTeX\"), 1500);\n      } catch (error) {\n        console.error(error);\n      }\n    });\n  });\n+</script>  </div> <div class="claim-body" data-astro-cid-sbzmajdw> <p>Modern recommender pipelines increasingly pair causal estimators with tooling for continuous experiment audits.</p> </div> </div> 
<h2 id="benchmarks--datasets">Benchmarks / datasets</h2>
<ul>
<li>Track online experiment datasets that include logging policies and intervention metadata.</li>
</ul> </section> <section class="card" data-astro-cid-w2hxe52l> <h2 data-astro-cid-w2hxe52l>Related topics and tendencies</h2> <div class="tag-row" data-astro-cid-w2hxe52l> <a class="chip" href="/Causal-AI/topics/off-policy-evaluation" data-astro-cid-w2hxe52l>Off-Policy Evaluation</a><a class="chip" href="/Causal-AI/topics/effect-estimation" data-astro-cid-w2hxe52l>Causal Effect Estimation</a><a class="chip" href="/Causal-AI/topics/causal-rl" data-astro-cid-w2hxe52l>Causal Reinforcement Learning</a> <a class="chip secondary" href="/Causal-AI/trends/causal-rl-ope-reliability" data-astro-cid-w2hxe52l>Causal RL + Off-Policy Evaluation Reliability</a><a class="chip secondary" href="/Causal-AI/trends/causal-agents-intervention-planning" data-astro-cid-w2hxe52l>Causal Agents + Intervention Planning</a> </div> </section><section class="card" data-astro-cid-w2hxe52l> <h2 data-astro-cid-w2hxe52l>Snapshot provenance</h2> <aside class="provenance" data-astro-cid-bysbcqd4> <h3 data-astro-cid-bysbcqd4>Provenance</h3> <div class="rows" data-astro-cid-bysbcqd4> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Snapshot</span> <strong data-astro-cid-bysbcqd4>2026-01-22</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Harvest window</span> <strong data-astro-cid-bysbcqd4>2025-12-23 to 2026-01-21</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Harvest source</span> <strong data-astro-cid-bysbcqd4>arxiv_api</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Last updated</span> <strong data-astro-cid-bysbcqd4>2026-01-22T02:10:00Z</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Ranking config</span> <strong data-astro-cid-bysbcqd4>2026-01-22/v1</strong> </div> <div data-astro-cid-bysbcqd4> <span data-astro-cid-bysbcqd4>Query pack</span> <strong data-astro-cid-bysbcqd4>2026-01-22/v1</strong> </div> </div> <a class="subtle provenance-link" href="/Causal-AI/trust/update-log" data-astro-cid-bysbcqd4>View update log</a> </aside>  <p class="subtle" data-astro-cid-w2hxe52l>Query: ti:causal AND (ti:recommender OR abs:recommendation OR abs:online experiment)</p> <p class="subtle" data-astro-cid-w2hxe52l>Window: 2025-12-23 to 2026-01-21</p> </section> <section data-astro-cid-w2hxe52l> <h2 data-astro-cid-w2hxe52l>Recent arXiv in this area</h2> <div class="grid" data-astro-cid-w2hxe52l> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1803.01422" data-astro-cid-saq65afh>DAGs with NO TEARS: Continuous Optimization for Structure Learning</a></h3> <div class="subtle" data-astro-cid-saq65afh>Xun Zheng, Bryan Aragam, Pradeep Ravikumar +1</div> </div> <p class="abstract" data-astro-cid-saq65afh>A continuous optimization approach to learning directed acyclic graphs that replaces combinatorial search with a smooth constraint.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer">arXiv:1803.01422</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2018-06-12</span> <span class="chip" data-astro-cid-saq65afh>v2</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>causal-discovery</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1907.02893" data-astro-cid-saq65afh>Invariant Risk Minimization</a></h3> <div class="subtle" data-astro-cid-saq65afh>Martin Arjovsky, Leon Bottou, Ishaan Gulrajani +1</div> </div> <p class="abstract" data-astro-cid-saq65afh>A principle for learning predictors that are stable across environments by enforcing invariance of optimal classifiers.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1907.02893" target="_blank" rel="noreferrer">arXiv:1907.02893</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2020-02-12</span> <span class="chip" data-astro-cid-saq65afh>v3</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>distribution-shift</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1705.08821" data-astro-cid-saq65afh>Causal Effect Inference with Deep Latent-Variable Models</a></h3> <div class="subtle" data-astro-cid-saq65afh>Yarin Gal, Ricardo Silva</div> </div> <p class="abstract" data-astro-cid-saq65afh>A deep latent-variable model (CEVAE) for causal effect inference with hidden confounding using variational methods.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1705.08821" target="_blank" rel="noreferrer">arXiv:1705.08821</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2017-10-03</span> <span class="chip" data-astro-cid-saq65afh>v1</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>effect-estimation</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1501.01332" data-astro-cid-saq65afh>Invariant Causal Prediction</a></h3> <div class="subtle" data-astro-cid-saq65afh>Peter Buhlmann, Jonas Peters, Nicolai Meinshausen</div> </div> <p class="abstract" data-astro-cid-saq65afh>A framework for causal discovery based on invariance of conditional distributions across environments.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1501.01332" target="_blank" rel="noreferrer">arXiv:1501.01332</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2016-05-02</span> <span class="chip" data-astro-cid-saq65afh>v2</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>distribution-shift</span> </div> </article>  </div> <h3 class="subhead" data-astro-cid-w2hxe52l>Trending</h3> <div class="grid" data-astro-cid-w2hxe52l> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1705.08821" data-astro-cid-saq65afh>Causal Effect Inference with Deep Latent-Variable Models</a></h3> <div class="subtle" data-astro-cid-saq65afh>Yarin Gal, Ricardo Silva</div> </div> <p class="abstract" data-astro-cid-saq65afh>A deep latent-variable model (CEVAE) for causal effect inference with hidden confounding using variational methods.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1705.08821" target="_blank" rel="noreferrer">arXiv:1705.08821</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2017-10-03</span> <span class="chip" data-astro-cid-saq65afh>v1</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>effect-estimation</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1501.01332" data-astro-cid-saq65afh>Invariant Causal Prediction</a></h3> <div class="subtle" data-astro-cid-saq65afh>Peter Buhlmann, Jonas Peters, Nicolai Meinshausen</div> </div> <p class="abstract" data-astro-cid-saq65afh>A framework for causal discovery based on invariance of conditional distributions across environments.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1501.01332" target="_blank" rel="noreferrer">arXiv:1501.01332</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2016-05-02</span> <span class="chip" data-astro-cid-saq65afh>v2</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>distribution-shift</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/1703.06856" data-astro-cid-saq65afh>Counterfactual Fairness</a></h3> <div class="subtle" data-astro-cid-saq65afh>Matt J. Kusner, Joshua Loftus, Chris Russell +1</div> </div> <p class="abstract" data-astro-cid-saq65afh>A causal definition of fairness based on comparing decisions across counterfactual worlds where protected attributes differ.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/1703.06856" target="_blank" rel="noreferrer">arXiv:1703.06856</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2018-03-12</span> <span class="chip" data-astro-cid-saq65afh>v2</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>causal-fairness</span> </div> </article> <article class="paper-card card" data-astro-cid-saq65afh> <div class="paper-head" data-astro-cid-saq65afh> <h3 data-astro-cid-saq65afh><a href="/Causal-AI/papers/2011.04216" data-astro-cid-saq65afh>DoWhy: An End-to-End Library for Causal Inference</a></h3> <div class="subtle" data-astro-cid-saq65afh>Amit Sharma, Emre Kiciman</div> </div> <p class="abstract" data-astro-cid-saq65afh>A practical Python library that unifies causal inference workflows across identification, estimation, and refutation.</p> <div class="meta" data-astro-cid-saq65afh> <a class="chip" href="https://arxiv.org/abs/2011.04216" target="_blank" rel="noreferrer">arXiv:2011.04216</a> <span class="chip secondary" data-astro-cid-saq65afh>Updated 2021-03-15</span> <span class="chip" data-astro-cid-saq65afh>v2</span> </div> <div class="tag-row" data-astro-cid-saq65afh> <span class="chip secondary" data-astro-cid-saq65afh>systems-tooling</span> </div> </article>  </div> </section> <section class="section continue"> <div class="container"> <div class="section-header"> <p class="eyebrow">Continue exploring</p> <h2>Follow the trail</h2> <p>Jump to a related topic, tendency, or a curated paper trail.</p> </div> <div class="card-grid"> <a class="card" href="/Causal-AI/topics/effect-estimation"> <h3>Causal Effect Estimation</h3> <p class="subtle">Estimating ATE/CATE and counterfactuals under explicit assumptions.</p> </a><a class="card" href="/Causal-AI/topics/off-policy-evaluation"> <h3>Off-Policy Evaluation</h3> <p class="subtle">Estimating policy effects from logged data and partial interventions.</p> </a> <a class="card" href="/Causal-AI/trends/causal-rl-ope-reliability"> <h3>Causal RL + Off-Policy Evaluation Reliability</h3> <p class="subtle">Causal RL is emphasizing reliable off-policy evaluation and intervention safety.</p> </a> <a class="card" href="/Causal-AI/observatory?trail=graphs-to-invariance"> <h3>Graphs to Invariance</h3> <p class="subtle">How structural discovery ideas evolved into robust, invariant prediction strategies.</p> </a> <a class="card callout-card" href="/Causal-AI/observatory?topic=effect-estimation"> <h3>Open the Observatory</h3> <p class="subtle">Follow live signals with filters preselected.</p> </a> </div> </div> </section>   </article> <aside class="doc-aside" data-astro-cid-fz5pa65a> <div class="card" data-astro-cid-fz5pa65a> <h3 data-astro-cid-fz5pa65a>On this page</h3> <ul data-astro-cid-fz5pa65a> <li data-astro-cid-fz5pa65a><a href="#the-causal-question" data-astro-cid-fz5pa65a>The causal question</a></li><li data-astro-cid-fz5pa65a><a href="#common-failure-modes-without-causality" data-astro-cid-fz5pa65a>Common failure modes without causality</a></li><li data-astro-cid-fz5pa65a><a href="#methods-that-show-up-a-lot" data-astro-cid-fz5pa65a>Methods that show up a lot</a></li><li data-astro-cid-fz5pa65a><a href="#benchmarks--datasets" data-astro-cid-fz5pa65a>Benchmarks / datasets</a></li> </ul> </div> <div class="card" data-astro-cid-fz5pa65a> <h3 data-astro-cid-fz5pa65a>Evidence summary</h3> <div class="tag-row" data-astro-cid-fz5pa65a> <a class="chip" href="https://arxiv.org/abs/1705.08821" target="_blank" rel="noreferrer">arXiv:1705.08821</a><a class="chip" href="https://arxiv.org/abs/2010.05761" target="_blank" rel="noreferrer">arXiv:2010.05761</a><a class="chip" href="https://arxiv.org/abs/1907.02893" target="_blank" rel="noreferrer">arXiv:1907.02893</a><a class="chip" href="https://arxiv.org/abs/1803.01422" target="_blank" rel="noreferrer">arXiv:1803.01422</a><a class="chip" href="https://arxiv.org/abs/2011.04216" target="_blank" rel="noreferrer">arXiv:2011.04216</a><a class="chip" href="https://arxiv.org/abs/2307.16405" target="_blank" rel="noreferrer">arXiv:2307.16405</a> </div> </div>  </aside> </div> </section>   </main> <footer class="site-footer" data-astro-cid-gcn2mc3v> <div class="container footer-inner" data-astro-cid-gcn2mc3v> <div class="footer-brand" data-astro-cid-gcn2mc3v> <strong data-astro-cid-gcn2mc3v>Causal AI Futures</strong> <p class="subtle" data-astro-cid-gcn2mc3v>A field guide to the intervention era.</p> <p class="subtle footer-credit" data-astro-cid-gcn2mc3v>Built by Gabriel Saco.</p> </div> <div class="footer-links" data-astro-cid-gcn2mc3v> <a href="/Causal-AI/about" data-astro-cid-gcn2mc3v>About</a><a href="https://github.com/gsaco/Causal-AI" target="_blank" rel="noreferrer" data-astro-cid-gcn2mc3v>GitHub</a><a href="/Causal-AI/trust/how-to-cite" data-astro-cid-gcn2mc3v>Cite</a> </div> </div> </footer>  <div class="cmdk" data-cmdk hidden data-astro-cid-wozhyvwc> <div class="cmdk-backdrop" data-cmdk-close data-astro-cid-wozhyvwc></div> <div class="cmdk-panel" role="dialog" aria-modal="true" aria-label="Command palette" data-astro-cid-wozhyvwc> <div class="cmdk-header" data-astro-cid-wozhyvwc> <input type="search" placeholder="Search papers, topics, and tendencies" data-cmdk-input data-astro-cid-wozhyvwc> <div class="cmdk-hint" data-astro-cid-wozhyvwc> <span class="kbd" data-astro-cid-wozhyvwc>Esc</span> to close
</div> </div> <div class="cmdk-results" data-cmdk-results data-astro-cid-wozhyvwc></div> </div> </div> <script src="/Causal-AI/pagefind/pagefind.js" defer></script> <script>
  const palette = document.querySelector("[data-cmdk]");
  const input = document.querySelector("[data-cmdk-input]");
  const results = document.querySelector("[data-cmdk-results]");
  const closeTriggers = document.querySelectorAll("[data-cmdk-close]");
  const openTriggers = document.querySelectorAll("[data-cmdk-open]");

  if (palette && input && results) {
    function openPalette() {
      palette.hidden = false;
      palette.classList.add("open");
      input.focus();
      results.innerHTML = "<p class='subtle'>Type to search the site.</p>";
    }

    function closePalette() {
      palette.classList.remove("open");
      palette.hidden = true;
    }

    closeTriggers.forEach((trigger) => trigger.addEventListener("click", closePalette));
    openTriggers.forEach((trigger) => trigger.addEventListener("click", openPalette));

    document.addEventListener("keydown", (event) => {
      if ((event.metaKey || event.ctrlKey) && event.key.toLowerCase() === "k") {
        event.preventDefault();
        openPalette();
      }
      if (event.key === "Escape" && !palette.hidden) {
        event.preventDefault();
        closePalette();
      }
    });

    palette.addEventListener("keydown", (event) => {
      if (event.key !== "Tab") return;
      const focusable = Array.from(palette.querySelectorAll("input, a, button, [tabindex='0']"))
        .filter((el) => !el.hasAttribute("disabled"));
      if (focusable.length === 0) return;
      const first = focusable[0];
      const last = focusable[focusable.length - 1];
      if (event.shiftKey && document.activeElement === first) {
        event.preventDefault();
        last.focus();
      } else if (!event.shiftKey && document.activeElement === last) {
        event.preventDefault();
        first.focus();
      }
    });

    async function runSearch(query) {
      if (!query) {
        results.innerHTML = "<p class='subtle'>Type to search the site.</p>";
        return;
      }
      if (!window.pagefind) return;
      const search = await window.pagefind.search(query);
      const entries = await Promise.all(search.results.slice(0, 6).map((r) => r.data()));
      results.innerHTML = entries
        .map((entry) => {
          return `
            <a class="cmdk-item" href="${entry.url}">
              <div>
                <strong>${entry.meta.title ?? entry.title}</strong>
                <p>${entry.excerpt}</p>
              </div>
              <span class="chip">${entry.meta.type ?? "result"}</span>
            </a>
          `;
        })
        .join("");
    }

    input.addEventListener("input", (event) => {
      runSearch(event.target.value);
    });

    results.addEventListener("click", (event) => {
      const target = event.target.closest("a");
      if (target) closePalette();
    });
  }
</script>  <script>
      const toggle = document.querySelector("[data-theme-toggle]");
      if (toggle) {
        toggle.addEventListener("click", () => {
          const current = document.documentElement.dataset.theme;
          const next = current === "dark" ? "light" : "dark";
          document.documentElement.dataset.theme = next;
          localStorage.setItem("theme", next);
        });
      }
    </script> </body> </html>